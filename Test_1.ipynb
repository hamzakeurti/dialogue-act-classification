{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1441, -2.6497, -0.0610],\n",
       "        [ 1.4158, -1.1405, -0.8985],\n",
       "        [-0.5867, -0.5864, -0.7786]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = torch.tensor([[0.1*i for k in range(3)] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.1000, 0.1000, 0.1000],\n",
       "        [0.2000, 0.2000, 0.2000],\n",
       "        [0.3000, 0.3000, 0.3000],\n",
       "        [0.4000, 0.4000, 0.4000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.6000, 0.6000, 0.6000],\n",
       "        [0.7000, 0.7000, 0.7000],\n",
       "        [0.8000, 0.8000, 0.8000],\n",
       "        [0.9000, 0.9000, 0.9000]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (10) must match the existing size (20) at non-singleton dimension 0.  Target sizes: [10, 3].  Tensor sizes: [20, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3d22103e2088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (10) must match the existing size (20) at non-singleton dimension 0.  Target sizes: [10, 3].  Tensor sizes: [20, 3]"
     ]
    }
   ],
   "source": [
    "_ = embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000],\n",
       "        [0.2000, 0.2000, 0.2000],\n",
       "        [0.3000, 0.3000, 0.3000]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocabulary_size,input_dim_audio, embedding_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.input_dim_audio = input_dim_audio\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_dim)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        text = data[0]\n",
    "        audio = data[1]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(100,20,300,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 16, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline.utils as utils\n",
    "import baseline.batcher as batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders,data_folders = utils.folders_info()\n",
    "vocabulary,data_dict,labels_dict,frames_dict = utils.init_dictionaries(folders,data_folders)\n",
    "\n",
    "loaders = batcher.initialize_tensors(folders,data_folders,vocabulary,data_dict,labels_dict,frames_dict,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = loaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for batch,(audio,text,label) in enumerate(train_loader):\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A.reshape(747*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "a,b,c = plt.hist([2, 2, 3, 3, 0, 3, 2, 1, 3, 1, 2, 4, 1, 3, 0, 2, 3, 0, 3, 3, 4, 0, 3, 1,\n",
    "        0, 4, 0, 1, 4, 3, 2, 1, 4, 0, 0, 0, 0, 4, 3, 1, 0, 4, 4, 2, 1, 0, 0, 1,\n",
    "        1, 3, 1, 0, 2, 1, 2, 0, 1, 2, 0, 1, 2, 1, 1, 4, 4, 4, 3, 4, 0, 1, 1, 0,\n",
    "        4, 1, 4, 1, 2, 0, 0, 1, 2, 4, 0, 1, 4, 2, 4, 2, 1, 2, 4, 4, 0, 1, 2, 2,\n",
    "        0, 1, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2940.0, 10557.0, 5361.0, 5618.0, 50224.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ 2940., 10557.,5361.,  5618.,50224.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline.utils as utils\n",
    "import baseline.batcher as batcher\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders,data_folders = utils.folders_info()\n",
    "\n",
    "batch_size = 100\n",
    "datasets = batcher.initialize_datasets(folders,data_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].__getitem__(0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'dev', 'test']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {'aa':1,'cc':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.json','w') as file:\n",
    "    file.write(json.dumps(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.json','r') as file:\n",
    "    vocabulary_2 = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_2['aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aa', 'cc'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha\n"
     ]
    }
   ],
   "source": [
    "A = 1\n",
    "if A:\n",
    "    print('ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.zeros((200,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'isTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-d0f6e70ac3fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mNone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'isTensor'"
     ]
    }
   ],
   "source": [
    "None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
